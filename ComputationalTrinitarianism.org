#+TITLE: Computational Trinitarianism
#+AUTHOR: Vojtěch Štěpančík
#+latex_header: \usepackage{amsthm}
#+latex_header: \usepackage{tikz-cd}
#+latex_header: \usepackage{prftree}
#+latex_header: \usepackage{apacite}

#+begin_export latex
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\newcommand{\stl}{\lambda^{\to}_{\ProdTypeCon}}

% Introduction rule
\newcommand{\Intro}[1]{$#1$-I}
% Elimination rule
\newcommand{\Elim}[1]{$#1$-E}

% Product type
\newcommand{\ProdTypeCon}{\land}
\newcommand{\ProdType}[2]{#1 \ProdTypeCon #2}
\newcommand{\ProdTypeFst}[1]{fst(#1)}
\newcommand{\ProdTypeSnd}[1]{snd(#1)}

% Generic category
\newcommand{\Cat}[1]{\mathcal{#1}}
% Class of objects in a category
\newcommand{\Obj}[1]{\mathcal{O}(\Cat{#1})}
% Class of arrows in a category
\newcommand{\Arr}[1]{hom(\Cat{#1})}
% Source of an arrow
\newcommand{\src}[1]{src(#1)}
% Destination of an arrow
\newcommand{\dest}[1]{dest(#1)}
% Arrow composition
\newcommand{\comp}[2]{#1 \circ #2}
% Hom set
\newcommand{\homset}[2]{hom(#1, #2)}
% Product factorizing morphism
\newcommand{\prodfact}[2]{\langle #1, #2 \rangle}
#+end_export

@@latex: \newpage@@
* Introduction
:PROPERTIES:
:UNNUMBERED:
:END:
This paper introduces the concept of /computational trinitarianism/, a term coined in \cite{HarperHT}, which presents a correspondence between ideas in logic, type theory, and category theory.

The usefulness of this idea is that new discoveries in one of the above mentioned fields have equivalents in the others, and finding these may provide new insights, triggering feedback loops and leading to more profound understandings of mathematics (TODO: wording?).

In the following sections, we focus on the links between the meet-implicational fragment of intuitionistic propositional logic, further referred to as intuitionistic logic, the simply typed \lambda-calculus with product types, further referred to as \(\stl\)-calculus, and closed Cartesian categories.

[[*Logic][Section 1]] introduces the logic used in the rest of the paper.
[[*Type theory][Section 2]] contains a summary of basic concepts of type theory, and presents the reader with a formulation of the \(\stl\)-calculus.
In [[*Logic and Type theory][Section 3]], we note the correspondence between the logic and calculus described in preceding sections.
In order to define the categorical semantics of the calculus, first an introduction to category theory is provided in [[*Category theory][Section 4]], leading to the definition and explanation of the class of categories called Cartesian closed, and then the semantics are described in [[Types and Category theory][Section 5]].

@@latex: \newpage@@
* Logic

Intuitionistic logic is a system that differs from classical logic by being construction-aware. To give an example, in classical logic, a proposition is intrinsically either true or false, so the formula $A \lor \neg A$ (/A or not A/) is true for all formulas $A$. This is called the law of excluded middle, and it does not universally hold in intuitionistic logic. That is because in intuitionistic logic, to assert that a proposition is true means to present a proof of the proposition according to the derivation rules of the specific logic. What it means is that to proclaim $A \lor \neg A$ to be true, one would actually need to devise either a proof of $A$ or a proof of $\neg A$. In this way, every proposition that is not an assumption must be accompanied by a proof "constructed" from proofs of its subformulas.

Proofs are constructed by sequencing derivation rules. For every connective in the specific logic, the derivation rules describe a way to introduce a formula with the connective (introduction rules, or construction), and a way to reduce a formula using the connective so that it doesn't contain it any longer (elimination rules, or deconstruction).

A derivation rule consists of a derivation line, above which are placed judgments called /premises/, and below is a judgment called /conclusion/. A judgment has the form $\Gamma \vdash A$, where $\Gamma$ is the /context/, which in set-theoretical interpretations is a set of assumptions, and $A$ is a proposition that is true when the assumptions hold.

Contexts can be merged using a comma, joining $\Gamma$ and $\Delta$ into $\Gamma,\Delta$. In a set-theoretical setting, the comma performs a set union with deduplication.

Derivation rules give a recipe for rewriting judgments regardless of semantic interpretation, purely in the context of the syntax of the logic it describes.

The rules for the logic we focus on are described in Figure [[fig:logic_derivations]]. The rule \Intro{\land}, read /conjunction introduction/, says that when one can deduce $A$ and $B$, then the same proofs lead to $A \land B$. The two elimination rules for the conjunction state that once a proof of $A \land B$ is given, either of its subformulas can be held to be true in further proofs.

The idea behind \Intro{\to} is such that if a proposition depends on its assumptions, one can remove a proposition $A$ from the context, and instead state that when $A$ is true, then the original proposition is also true. \Elim{\to} is also known as /modus ponens/, and it states that when the antecedent in the implication can be proved to be true, than the consequent holds.

#+name: fig:logic_derivations
#+caption: Derivation rules for the implicative fragment of intuitionistic propositional logic with conjunction
#+begin_figure
$$
\prftree[r]{Id}
{A \vdash A}
$$

$$
\prftree[r]{\Intro{\land}}
{\Gamma \vdash A}
{}
{\Delta \vdash B}
{\Gamma, \Delta \vdash A \land B}
\hspace{1cm}
\prftree[r]{\Elim{\land}$_1$}
{\Gamma \vdash A \land B}
{\Gamma \vdash A}
\hspace{1cm}
\prftree[r]{\Elim{\land}$_2$}
{\Gamma \vdash A \land B}
{\Gamma \vdash B}
$$

$$
\prftree[r]{\Intro{\to}}
{\Gamma, A \vdash B}
{\Gamma \vdash A \to B}
\hspace{1cm}
\prftree[r]{\Elim{\to}}
{\Gamma \vdash A \to B}
{}
{\Delta \vdash A}
{\Gamma, \Delta \vdash B}
$$
#+end_figure

@@latex:\newpage@@
Sometimes, when building a new proof from existing parts, we can produce proofs with redundancies. This happens when a rule for introducing a connective is applied, and then the connective is eliminated in the very next step. To simplify proofs, we introduce rewriting rules for proof reduction, which are described in Figure [[fig:proof_reduct]].

Two reduction rules for the conjunction exist, but only one is shown, the other is defined symmetrically. It describes a situation where an existing proof of $A$ is combined with a proof of $B$ to prove the conjunction, and then asks for $A$ back. In that case, there is no reason for $B$ to appear at all, and the proof can forget that branch altogether.

The idea behind reduction of implication is that if there is a proof of $A$ in some context $\Delta$, and another proof has $A$ as an assumption, then one can directly substitute the assumption of $A$ for its proof in the derivation tree for $B$, merging the assumption contexts.

(TODO: explicitly mention weakening and contraction)

#+name: fig:proof_reduct
#+caption: Proof reduction rules
#+begin_figure
$$
\prftree[r]{\Elim{\land}$_1$}
{\prftree[r]{\Intro{\land}}
{A \vdash A}
{}
{B \vdash B}
{A,B \vdash A \land B}}
{A,B \vdash A}
\hspace{1cm}\Rightarrow\hspace{1cm}
\prftree[r]{Id}
{A \vdash A}
{A \vdash A}
$$

$$
\prftree[r]{\Elim{\to}}
{\prftree[r]{\Intro{\to}}
{\Gamma, A \vdash B}
{\Gamma \vdash A \to B}}
{}
{\Delta \vdash A}
{\hspace{1.5em}}
{\Gamma, \Delta \vdash B}
\hspace{1cm}\Rightarrow\hspace{1cm}
\Gamma, \Delta \vdash B
$$
#+end_figure

* Type theory

Type theory is a study of formal systems in which a terms has an associated label called /type/, and rules for constructing the terms include the description of their behavior on the types.

More precisely, in constructive mathematics, a mathematical object is created by construction, and the type of an object is the type of construction used to create it \cite{bauerSE}.

One such type system is the simply typed \lambda-calculus, or STLC, which extends the untyped \lambda-calculus by introducing a set of /base types/, and inductively generates all its types with the $\to$ binary type operator, where the type $A \to B$ is the type of functions from type $A$ to type $B$. A term $t$ of type $A$ is expressed as $t: A$.

The STLC recognizes three forms for its terms, very much like the untyped \lambda-calculus. These are /variables/, of the form $x: A$, where $x$ is an atom and $A$ is a type, then /abstractions/, which represent functions, and have the form $\lambda x.t: A \to B$, where $x: A$, $t: B$, and $x$ is a free variable in $t$, becoming bound by the abstraction. Finally, abstractions can be used in an /application/, which, given the terms $f: A \to B$ and $t: A$, yields the term $f(t): B$. Application forms can be further simplified by performing /\(\beta\)-reduction/, defined using term substitution as $(\lambda x.t)(s) \to t[s/x]$, where free occurrences of $x$ in $t$ are rewritten to $s$. Performing a reduction is synonymous with /evaluating/ a program.

@@latex:\newpage@@
We define an extension of the simply typed \lambda-calculus by introducing the binary product type operator $\ProdTypeCon$, producing types of the form $\ProdType{A}{B}$, which represent tuples of one object of type $A$ and one object of type $B$. We call this extension the \(\stl\)-calculus, and the construction rules are listed in Figure [[fig:type_derivation]].

#+name: fig:type_derivation
#+caption: Derivation rules for the \(\stl\)-calculus
#+begin_figure
$$
\prftree[r]{Id}
{x: A \vdash x: A}
$$

$$
\prftree[r]{\Intro{\ProdTypeCon}}
{\Gamma \vdash x: A}
{}
{\Delta \vdash y: B}
{\Gamma, \Delta \vdash \prodfact{x}{y}: \ProdType{A}{B}}
\hspace{0.5cm}
\prftree[r]{\Elim{\ProdTypeCon}$_1$}
{\Gamma \vdash t: \ProdType{A}{B}}
{\Gamma \vdash \ProdTypeFst{t}: A}
\hspace{0.5cm}
\prftree[r]{\Elim{\ProdTypeCon}$_2$}
{\Gamma \vdash t: \ProdType{A}{B}}
{\Gamma \vdash \ProdTypeSnd{t}: B}
$$

$$
\prftree[r]{\Intro{\to}}
{\Gamma, x: A \vdash t: B}
{\Gamma \vdash \lambda x.t: A \to B}
\hspace{0.5cm}
\prftree[r]{\Elim{\to}}
{\Gamma \vdash f: A \to B}
{\Delta \vdash t: A}
{\Gamma, \Delta \vdash f(t): B}
$$
#+end_figure

The new forms introduced are /tuples/, written as $\prodfact{x}{y}: \ProdType{A}{B}$, which represent a pair of terms, and left and right /projections/, written as $\ProdTypeFst{t}: A$ and $\ProdTypeSnd{t}: B$, respectively, assuming a term $t: \ProdType{A}{B}$. This new syntax allows for more redundant forms of terms, which can be simplified using /\(\pi\)-reduction/ via the evaluation steps $\ProdTypeFst{\prodfact{x}{y}} \to x$ and $\ProdTypeSnd{\prodfact{x}{y}} \to y$.

(TODO: maybe research more on whether $f(t): A$ and $fst(t)$ are valid, or if we need to introduce the concept of canonical representations)

The language is once again described with derivation rules, with zero or more premises above and one conclusion below the line. The context in a judgment now stands for a collection of typed variables, and contains the variables that are free in the term on the right side of the turnstile. In this way, the \Intro{\to} rule can be intuitively interpreted by taking a variable $x: A$, and instead of treating it as free, we remove it from the context and bind it with an abstraction.

* Logic and Type theory

Looking at figures [[fig:logic_derivations]] and [[fig:type_derivation]], one can observe some similarity. Indeed, if we were to remove the terms from the derivation rules for the \(\stl\)-calculus, the two would be exactly the same. In other words, the /types/ serve the same role as /propositions/, which is where the idea of "propositions are types" came from.

However, the correspondence goes deeper. Every form of a term in the calculus has exactly one rule that creates it, therefore looking at the program in the conclusion of a derivation tree has one-to-one correspondence with the tree itself. Since the tree is how intuitionistic logic represents a proof, one comes to the conclusion that "programs are proofs". A corollary of this statement is that determining whether a proposition in the logic is provable is the same as deciding if a type in the corresponding type theory is inhabitable.

The final level of the correspondence is one between the reduction operations of proofs and terms. \pi-reductions of a term correspond to a reduction of a proof that introduces and then throws away a conjunction, and reducing a implication in a proof has the exact same effect as substituting the argument variable with its value in the term under \beta-reduction.

@@latex: \newpage@@
* Category theory

This chapter introduces concepts from category theory necessary to introduce categorical semantics for the calculus defined above.

We start by defining what a category even /is/.

#+name: category-def
#+begin_definition
A *category* $\Cat{K}$ is a pair of classes, namely the class of its objects, denoted $\Obj{K}$, and the class of the arrows between these objects, denoted $\Arr{K}$, with the following structure:

1. For every arrow $a \in \Arr{K}$, we can identify the source $\src a \in \Obj{K}$ and destination $\dest a \in \Obj{K}$ of that arrow. We often denote such an arrow graphically, so that if $\src a = X$ and $\dest a = Y$, we write
   \begin{tikzcd} X \arrow[r, "a"] & Y \end{tikzcd}
   or
   $a: X \to Y$.
2. For every object $X \in \Obj{K}$, there exists an arrow $id_X \in \Arr{K}$, called the identity arrow (or simply identity) on X, such that $\src{id_X} = \dest {id_X} = X$. We omit the subscript in situations where it can be inferred from context.
3. For all arrows $a, b \in \Arr{K}$ where $\dest a = \src b$, their composition, denoted $\comp b a: \src a \to \dest b$ is also an arrow in $\Arr{K}$.

   1. This composition operator is associative. That is, for $a: X \to Y$, $b: Y \to Z$, $c: Z \to W$ in $\Arr{K}$, it is true that $\comp c (\comp b a) = \comp {(\comp c b)} a$

   2. The identity arrows are identities with respect to the composition operator. That is, for $a: X \to Y$ in $\Arr{K}$, the equality $\comp a id_X = a = \comp {id_Y} a$ holds.
#+end_definition

As a convention, and unless the context demands otherwise, capital cursive letters from the middle of the alphabet are used for categories, capital letters from the end of the alphabet are used for objects and lowercase letters from the beginning of the alphabet are used for arrows, with an occasional apostrophe thrown in for cases where there's a need for additional dimension in differentiation.

We can think of a category as a collection of some unknown objects with arrows between them, with the additional structure that any object has an arrow pointing to itself, and a recipe to "correctly" paste one arrow after another to get a new one.

Since the requirements for being a category are quite lax, we can find many examples, some of which are listed below.

The category of sets, denoted *Set*, has sets for objects and set functions for arrows. We can see that 1. is satisfied by the fact that functions have a domain and a codomain associated with them. Furthermore, the identity function is defined for every set, and also behaves as an identity for function composition, which is associative, making *Set* a category.

A non-obvious observation is that every poset $P(A, \le)$ can be looked at as a category. The objects are the elements of the underlying set $A$, and an arrow between $x, y \in A$ either exists when $x \le y$, or it doesn't. Because the relation $\le$ is reflexive, it holds for every x in $A$ that $x \le x$, and because it is transitive, we know that if there is an arrow from $x$ to $y$ ($x \le y$) and one from $y$ to $z$ ($y \le z$), then there is also an arrow from $x$ to $z$ ($x \le z$). Since there can only be one arrow between any two objects, associativity and identity element are guaranteed for free. Categories which only permit one or zero arrows from one object to another are also called /thin/ or /posetal/.

Other examples of categories include those whose objects are some predefined algebras and the arrows are homomorphisms in said algebra, i.e. *Mon* for the category of monoids or *Grp* for the category of groups.

Equipped with a notion of a category, we can define operations on objects in an arbitrary category. One such operation we need for the purposes of this paper is the product, which is a generalization of the Cartesian product from set theory, lifted into categories.

#+begin_definition
A *categorical product* of two objects $X$ and $Y$ in a category $\Cat{K}$ is another object in the same category, often denoted $X \times Y$, equipped with two arrows, $\pi_X: X \times Y \to X$ and $\pi_Y: X \times Y \to Y$, satisfying the following property:

For every other object $W \in \Obj{K}$ and a pair of arrows $p: W \to X$ and $q: W \to Y$, there exists a unique arrow $m: W \to X \times Y$ that factorizes $p$ and $q$ through $X \times Y$. That is to say, $p = \comp{\pi_X}{m}$ and $q = \comp{\pi_Y}{m}$. This factorizing arrow is also denoted $\prodfact{p}{q}$.
#+end_definition

We can see why the Cartesian product of two sets $X$ and $Y$ is the product of the corresponding objects in the category *Set*: First of all, the Cartesian product $X \times Y$ is itself a set, so it is a valid object in *Set*, and we can look at individual members of any tuple therein, giving us the two projection onto its components. Secondly, if we are given another set $W$ with functions $p$ and $q$ into $X$ and $Y$ respectively, we can construct a function into the product by taking the images under both $p$ and $q$ and packaging them into a tuple: $m(w) = (p(w), q(w))$. It's trivial to see that the arrows line up.

Another example that may not be obvious at first is the meet of two objects in a posetal category. The definition of a posetal category tells us that a factoring arrow either exists or doesn't, so the definition amounts to finding an object that is less than $X$ and $Y$ and with the property that every other object that is less than both $X$ and $Y$ is also less than the product, which is exactly the definition of a meet.

The binary product can be naturally extended to a product of any finite number of objects greater than two.

#+begin_definition
A *final object* (also called *terminal object* or $1$) is an object for which there is exactly one arrow pointing to it from every other object in the same category.
#+end_definition

In *Set*, the final object is the singleton set, since from every other set, there is a function projecting every element to the single element of the singleton set.
Similarly in a posetal category, the final object is such an element that all other objects are less than or equal, which amounts to the definition of the greatest element.

The final object is the identity element for the categorical product, that is to say $X \times 1 = X = 1 \times X$. Given any object $X$, we have the identity arrow $id_X: X \to X$, and the unique arrow going to $1$, denoted $const_X: X \to 1$. Then, for every other object $Y$ and a pair of arrows $p: Y \to X$ and $q: Y \to 1$, we reason that $q = const_Y$, because there is only one arrow from $Y$ to $1$, and that the factoring arrow is $p$ itself, since the identity can be composed with arrows without effect, achieving $p = \comp{p}{id_X}$.

Having an identity element to the categorical product, we can intuitively define nullary and unary products of an object $X$ as the final object and $X$ itself, respectively.

#+begin_definition
An *exponential* of two objects $X$ and $Y$ in a category $\Cat{K}$ is another object in the same category, often denoted $X^Y$, equipped with an arrow $eval: X^Y \times Y \to X$, satisfying the following property:

For every other object $Z$ in $\Obj{K}$ and an arrow $h: Z \times Y \to X$, there exists a unique arrow $h^\flat: Z \to X^Y$
#+end_definition

Exponentials serve as an abstraction of functions, allowing one to represent arrows between two objects as another object in the same category. This is hinted at by the suggestive naming of the arrow $eval$, whose name stems from its role of taking a "function" object and an "argument" object, and "applying" the second to the first. In this light, the property in the definition can be seen as introducing currying, a term familiar to many functional programmers, which states that a function taking a tuple, essentially two arguments, can be partially applied, or provided with just one argument, returning another function that needs to be supplied with the other argument in order to be evaluated.


#+begin_definition
A *closed Cartesian category* $\Cat{K}$ is a category satisfying the following properties:

1. $\Cat{K}$ has all finite products
2. For every pair of objects $X, Y \in \Obj{K}$, their exponent $X^Y$ exists in $\Cat{K}$
#+end_definition

A closed Cartesian category is therefore a category that has a final object, all binary products, and the arrows between two objects have a concrete representation in the form of another object in the category.

@@latex: \newpage@@
* Types and Category theory

* TODO List of common variable names
| Proposition, Type    | $A$, $B$               |
| Context              | \Gamma, \Delta         |
| Variable             | $x$, $y$               |
| Term                 | $s$, $t$               |
| Category             | $\Cat{K}$, $\Cat{L}$   |
| Object in a category | $X$, $Y$, $X'$         |
| Arrow in a category  | $a$, $b$, $a'$, $id_X$ |
| Final object         | $T$                    |


#+begin_export latex
\bibliography{ComputationalTrinitarianism}
\bibliographystyle{apacite}
#+end_export

* COMMENT TODO [2/6]
- [ ] Examples of transferred ideas in [[*Introduction][Introduction]]
- [X] Proof reduction
- [ ] Motivations for definitions
- [X] Examples for categories
- [ ] Unify writing style -> narrative vs impersonal declarative
- [ ] Sources
